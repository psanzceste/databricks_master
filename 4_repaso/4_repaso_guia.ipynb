{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a09443b-a6c3-4fd0-a16e-ae04a357e8ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"es\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Pr√°ctica Databricks Fundamentals ¬∑ Unity Catalog ¬∑ PySpark</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, Helvetica, sans-serif;\n",
    "            line-height: 1.6;\n",
    "            margin: 40px;\n",
    "            color: #222;\n",
    "        }\n",
    "        h1, h2, h3 {\n",
    "            color: #B22222;\n",
    "        }\n",
    "        code {\n",
    "            background-color: #f4f4f4;\n",
    "            padding: 2px 4px;\n",
    "            border-radius: 4px;\n",
    "            font-size: 0.95em;\n",
    "        }\n",
    "        pre {\n",
    "            background-color: #f4f4f4;\n",
    "            padding: 12px;\n",
    "            border-radius: 6px;\n",
    "            overflow-x: auto;\n",
    "        }\n",
    "        .box {\n",
    "            border-left: 4px solid #B22222;\n",
    "            background-color: #fafafa;\n",
    "            padding: 12px;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "        .exercise {\n",
    "            border-left: 4px solid #1E90FF;\n",
    "            background-color: #f0f8ff;\n",
    "            padding: 12px;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "        .warning {\n",
    "            border-left: 4px solid #FF8C00;\n",
    "            background-color: #fff5e6;\n",
    "            padding: 12px;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "\n",
    "<h1>Repaso Databricks Fundamentals ¬∑ Unity Catalog ¬∑ PySpark</h1>\n",
    "\n",
    "<p>\n",
    "Esta pr√°ctica forma parte de una sesi√≥n de m√°ster orientada a consolidar los conceptos\n",
    "fundamentales de <b>Databricks</b>, <b>Unity Catalog</b> y <b>PySpark</b> mediante ejecuci√≥n real\n",
    "de c√≥digo en un notebook.\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "<h2>üß± Contexto: Arquitectura Databricks (Repaso)</h2>\n",
    "\n",
    "<p>Antes de empezar, recuerda los principales componentes:</p>\n",
    "\n",
    "<ul>\n",
    "    <li><b>Workspace</b>: entorno colaborativo (notebooks, jobs, repos)</li>\n",
    "    <li><b>Cluster</b>: recursos de c√≥mputo donde se ejecuta Spark</li>\n",
    "    <li><b>DBFS / External Storage</b>: capa de almacenamiento</li>\n",
    "    <li><b>Delta Lake</b>: formato transaccional sobre Parquet</li>\n",
    "    <li><b>Unity Catalog</b>: metastore centralizado de gobierno</li>\n",
    "</ul>\n",
    "\n",
    "---\n",
    "\n",
    "<h2>üìÅ Dataset</h2>\n",
    "\n",
    "<p>Trabajaremos con un archivo CSV de ventas con la siguiente estructura:</p>\n",
    "\n",
    "<pre>\n",
    "order_id | product | quantity | price | country\n",
    "</pre>\n",
    "\n",
    "El archivo se encuentra en este github: [Enlace](https://github.com/psanzceste/databricks_master/4_repaso/data.git)\n",
    "\n",
    "Cuando te lo descargues, ve a Unity Catalog, abre un catalogo, abre un schema, abre un volumen y subel√≥ ah√≠\n",
    "\n",
    "---\n",
    "\n",
    "<h2>üì• Paso 1 ‚Äì Carga de datos con PySpark</h2>\n",
    "\n",
    "<p>\n",
    "Usaremos la API de lectura de Spark para cargar el CSV como un DataFrame distribuido. Quiero que primero se examine la informaci√≥n del archivo y luego se decida sobre los diferentes par√°metros de la funci√≥n\n",
    "</p>\n",
    "\n",
    "<pre>\n",
    "spark.read\n",
    "    .option(\"header\", ...)\n",
    "    .option(\"inferSchema\", ...)\n",
    "    .csv(...)\n",
    "</pre>\n",
    "\n",
    "<p>\n",
    "Una vez cargado, utilizaremos <code>display()</code> para explorar visualmente los datos.\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "<div class=\"exercise\">\n",
    "<h3>‚úçÔ∏è Ejercicio 1 ‚Äì Exploraci√≥n b√°sica</h3>\n",
    "<ul>\n",
    "    <li>Examinar el contenido de CSV</li>\n",
    "    <li>Cargar correctamente el DataFrame</li>\n",
    "    <li>Muestra el esquema del DataFrame</li>\n",
    "    <li>Cuenta el n√∫mero total de registros</li>\n",
    "    <li>Identifica los tipos de datos detectados por Spark</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<h2>üîß Paso 2 ‚Äì Transformaciones con PySpark</h2>\n",
    "\n",
    "<p>\n",
    "Aplicaremos una transformaci√≥n sencilla para ilustrar el modelo inmutable de Spark:\n",
    "crear una nueva columna calculada.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Ejemplo conceptual:\n",
    "</p>\n",
    "\n",
    "<prep>\n",
    "total_amount = quantity * price\n",
    "</pre>\n",
    "<pre>\n",
    "df_transformed = (\n",
    "    df\n",
    "    .withColumn(...., col(...) * col(...))\n",
    ")\n",
    "</pre>\n",
    "\n",
    "<p>\n",
    "Ve al notebook, pega el c√≥digo y muestra el resultado\n",
    "</p>\n",
    "\n",
    "<div class=\"box\">\n",
    "<b>Concepto clave:</b> las transformaciones en Spark son <i>lazy</i>. No se ejecutan\n",
    "hasta que se lanza una acci√≥n.\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div class=\"exercise\">\n",
    "<h3>‚úçÔ∏è Ejercicio 2 ‚Äì Transformaciones</h3>\n",
    "<ul>\n",
    "    <li>Crea una columna <code>total_amount</code></li>\n",
    "    <li>Filtra las ventas con importe mayor a 100</li>\n",
    "    <li>Agrupa por pa√≠s y calcula el total de ventas</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<h2>üß† Paso 3 ‚Äì Introducci√≥n a Unity Catalog</h2>\n",
    "\n",
    "<p>\n",
    "Unity Catalog proporciona un modelo jer√°rquico de gobierno:\n",
    "</p>\n",
    "\n",
    "<pre>\n",
    "Metastore\n",
    " ‚îî‚îÄ‚îÄ Catalog\n",
    "     ‚îî‚îÄ‚îÄ Schema\n",
    "         ‚îî‚îÄ‚îÄ Table / View / Function\n",
    "</pre>\n",
    "\n",
    "<p>\n",
    "Cada nivel puede tener permisos expl√≠citos, desacoplando seguridad y almacenamiento.\n",
    "</p>\n",
    "\n",
    "<div class=\"box\">\n",
    "<b>Importante:</b> Unity Catalog gobierna el acceso a los datos, no su procesamiento.\n",
    "</div>\n",
    "\n",
    "<p>\n",
    "Analiza la estructura de tu Unity Catalog para ver si tiene sentido crear una nueva. La idea es que la jerarqu√≠a creada tenga sentido para el resto de las clases. Si crees que lo correcto ser√≠a crear alg√∫n objeto, este es el momento de crear un nuevo Catalogo o un nuevo Schema.\n",
    "\n",
    "Si quieres crear uno nuevo, ve al Notebook, ve al Paso 3, configura los nombres que quieras darle a cada cosa y ejecuta\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "<h2>üíæ Paso 4 ‚Äì Crear una tabla Delta gestionada</h2>\n",
    "\n",
    "<p>\n",
    "Persistiremos el DataFrame transformado como una tabla gobernada.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Esto implica:\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "    <li>Formato Delta Lake</li>\n",
    "    <li>Metadatos registrados en Unity Catalog</li>\n",
    "    <li>Ubicaci√≥n gestionada por Databricks</li>\n",
    "</ul>\n",
    "\n",
    "Para ello ejecuta en el Notebook este comando modificando las cosas que haya que hacer\n",
    "\n",
    "<pre>\n",
    "...write.mode(\"overwrite\").saveAsTable(...)\n",
    "</pre>\n",
    "\n",
    "---\n",
    "\n",
    "<h3>üîç Spark SQL vs PySpark</h3>\n",
    "\n",
    "<p>\n",
    "Una vez creada la tabla, podr√°s consultarla tanto con PySpark\n",
    "\n",
    "<pre>\n",
    "df = spark.table(\"master.repaso.sales_table\")\n",
    "</pre>\n",
    "\n",
    "Como con SQL:\n",
    "</p>\n",
    "\n",
    "<pre>\n",
    "SELECT * FROM tu_catalogo.tu_schema.sales_table;\n",
    "</pre>\n",
    "\n",
    "<p>\n",
    "Ambos enfoques comparten el mismo motor de ejecuci√≥n. Compruebalo en el Notebook\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "<div class=\"exercise\">\n",
    "<h3>‚úçÔ∏è Ejercicio 3 ‚Äì Gobierno de datos</h3>\n",
    "<ul>\n",
    "    <li>Guarda el DataFrame como tabla</li>\n",
    "    <li>Consulta los permisos asociados a la tabla. Para ello ve a Unity Catalog y mira en las propiedades de la tabla</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<h2>‚úÖ Conclusiones</h2>\n",
    "\n",
    "<ul>\n",
    "    <li>Databricks unifica ingesti√≥n, procesamiento y gobierno</li>\n",
    "    <li>PySpark es la API principal para transformaciones distribuidas</li>\n",
    "    <li>Unity Catalog centraliza seguridad y metadatos</li>\n",
    "    <li>Delta Lake es el est√°ndar para persistencia</li>\n",
    "</ul>\n",
    "\n",
    "<div class=\"box\">\n",
    "<b>Mensaje final:</b> Databricks no es solo Spark en la nube, es una plataforma\n",
    "de datos gobernada de extremo a extremo.\n",
    "</div>\n",
    "\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d91c24d-c3ae-4ab9-a42f-6ab946328857",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Para consultar la tabla con PySpark, puedes usar el siguiente c√≥digo:\n",
    "\n",
    "python\n",
    "df = spark.table(\"master.repaso.sales_table\")\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4_repaso_guia",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
